{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "d = loadmat('dataset/resultados_w1000pts.mat')\n",
    "ptrafo1 = pd.DataFrame(d['Ptrafo1'].transpose().flatten(), columns = ['Ptrafo1'])\n",
    "ptrafo2 = pd.DataFrame(d['Ptrafo2'].transpose().flatten(), columns = ['Ptrafo2'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fv = loadmat('dataset/FVcurves1000pts.mat')\n",
    "fv_12 = pd.DataFrame(fv['FV_w'].flatten(), columns = ['FV_12'])\n",
    "fv_18 = pd.DataFrame(fv['FV_w'].flatten(), columns = ['FV_18'])\n",
    "fv_25 = pd.DataFrame(fv['FV_w'].flatten(), columns = ['FV_25'])\n",
    "fv_29 = (1/47) * pd.DataFrame(fv['FV_w'].flatten(), columns = ['FV_29'])\n",
    "fv_32 = (1/42) * pd.DataFrame(fv['FV_w'].flatten(), columns = ['FV_32'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vref1 = np.zeros([144, 1000])\n",
    "vref2 = np.zeros([144, 1000])\n",
    "a = 0\n",
    "b = 25\n",
    "for i in range(144):\n",
    "  for j in range(len(d['Tensao'][0])):\n",
    "    vref1[i][j] = d['Tensao'][a][j]\n",
    "    vref2[i][j] = d['Tensao'][b][j]\n",
    "  a = a + 42\n",
    "  b = b + 42\n",
    "\n",
    "vref1 = pd.DataFrame(vref1.transpose().flatten(), columns = ['Vref1'])\n",
    "vref2 = pd.DataFrame(vref2.transpose().flatten(), columns = ['Vref2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ptrafo1</th>\n",
       "      <th>Ptrafo2</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>...</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q35</th>\n",
       "      <th>Q36</th>\n",
       "      <th>Q37</th>\n",
       "      <th>Q38</th>\n",
       "      <th>Q39</th>\n",
       "      <th>Q40</th>\n",
       "      <th>Q41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>0.337678</td>\n",
       "      <td>0.093012</td>\n",
       "      <td>0.009481</td>\n",
       "      <td>0.009348</td>\n",
       "      <td>0.010640</td>\n",
       "      <td>0.005741</td>\n",
       "      <td>0.005507</td>\n",
       "      <td>0.020521</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.005551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000255</td>\n",
       "      <td>0.000253</td>\n",
       "      <td>0.006299</td>\n",
       "      <td>0.005716</td>\n",
       "      <td>0.005786</td>\n",
       "      <td>0.012480</td>\n",
       "      <td>0.021099</td>\n",
       "      <td>0.013912</td>\n",
       "      <td>0.021721</td>\n",
       "      <td>0.005749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>0.305996</td>\n",
       "      <td>0.084692</td>\n",
       "      <td>0.009507</td>\n",
       "      <td>0.008017</td>\n",
       "      <td>0.010989</td>\n",
       "      <td>0.005431</td>\n",
       "      <td>0.005488</td>\n",
       "      <td>0.018590</td>\n",
       "      <td>0.018987</td>\n",
       "      <td>0.005639</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>0.005627</td>\n",
       "      <td>0.005359</td>\n",
       "      <td>0.005044</td>\n",
       "      <td>0.010697</td>\n",
       "      <td>0.019658</td>\n",
       "      <td>0.013124</td>\n",
       "      <td>0.019688</td>\n",
       "      <td>0.005284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>0.291301</td>\n",
       "      <td>0.079540</td>\n",
       "      <td>0.008719</td>\n",
       "      <td>0.007536</td>\n",
       "      <td>0.010365</td>\n",
       "      <td>0.005265</td>\n",
       "      <td>0.005271</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>0.018926</td>\n",
       "      <td>0.005178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000206</td>\n",
       "      <td>0.000228</td>\n",
       "      <td>0.005530</td>\n",
       "      <td>0.005308</td>\n",
       "      <td>0.005564</td>\n",
       "      <td>0.010815</td>\n",
       "      <td>0.017404</td>\n",
       "      <td>0.012537</td>\n",
       "      <td>0.017385</td>\n",
       "      <td>0.004822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>0.277902</td>\n",
       "      <td>0.077530</td>\n",
       "      <td>0.009021</td>\n",
       "      <td>0.007408</td>\n",
       "      <td>0.010420</td>\n",
       "      <td>0.004760</td>\n",
       "      <td>0.004796</td>\n",
       "      <td>0.017365</td>\n",
       "      <td>0.016025</td>\n",
       "      <td>0.005020</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000178</td>\n",
       "      <td>0.000210</td>\n",
       "      <td>0.004860</td>\n",
       "      <td>0.004929</td>\n",
       "      <td>0.005253</td>\n",
       "      <td>0.010727</td>\n",
       "      <td>0.017573</td>\n",
       "      <td>0.013319</td>\n",
       "      <td>0.015857</td>\n",
       "      <td>0.004839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>0.279065</td>\n",
       "      <td>0.078561</td>\n",
       "      <td>0.008104</td>\n",
       "      <td>0.007931</td>\n",
       "      <td>0.010299</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>0.004836</td>\n",
       "      <td>0.016200</td>\n",
       "      <td>0.016499</td>\n",
       "      <td>0.004801</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000185</td>\n",
       "      <td>0.000211</td>\n",
       "      <td>0.004941</td>\n",
       "      <td>0.005104</td>\n",
       "      <td>0.004923</td>\n",
       "      <td>0.010776</td>\n",
       "      <td>0.017839</td>\n",
       "      <td>0.012315</td>\n",
       "      <td>0.017587</td>\n",
       "      <td>0.004897</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143995</th>\n",
       "      <td>0.857367</td>\n",
       "      <td>0.235687</td>\n",
       "      <td>0.025086</td>\n",
       "      <td>0.023784</td>\n",
       "      <td>0.028559</td>\n",
       "      <td>0.014306</td>\n",
       "      <td>0.014914</td>\n",
       "      <td>0.050059</td>\n",
       "      <td>0.051772</td>\n",
       "      <td>0.015628</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000572</td>\n",
       "      <td>0.000698</td>\n",
       "      <td>0.015604</td>\n",
       "      <td>0.015474</td>\n",
       "      <td>0.017490</td>\n",
       "      <td>0.028037</td>\n",
       "      <td>0.049220</td>\n",
       "      <td>0.034343</td>\n",
       "      <td>0.057983</td>\n",
       "      <td>0.015990</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143996</th>\n",
       "      <td>0.740003</td>\n",
       "      <td>0.201916</td>\n",
       "      <td>0.020649</td>\n",
       "      <td>0.020129</td>\n",
       "      <td>0.028740</td>\n",
       "      <td>0.013905</td>\n",
       "      <td>0.012886</td>\n",
       "      <td>0.046503</td>\n",
       "      <td>0.046473</td>\n",
       "      <td>0.012015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000447</td>\n",
       "      <td>0.000611</td>\n",
       "      <td>0.013078</td>\n",
       "      <td>0.012686</td>\n",
       "      <td>0.012914</td>\n",
       "      <td>0.025388</td>\n",
       "      <td>0.043782</td>\n",
       "      <td>0.033284</td>\n",
       "      <td>0.046765</td>\n",
       "      <td>0.012852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143997</th>\n",
       "      <td>0.802869</td>\n",
       "      <td>0.220284</td>\n",
       "      <td>0.023419</td>\n",
       "      <td>0.021639</td>\n",
       "      <td>0.027228</td>\n",
       "      <td>0.013467</td>\n",
       "      <td>0.015262</td>\n",
       "      <td>0.050713</td>\n",
       "      <td>0.050593</td>\n",
       "      <td>0.014626</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000494</td>\n",
       "      <td>0.000631</td>\n",
       "      <td>0.013512</td>\n",
       "      <td>0.013954</td>\n",
       "      <td>0.014343</td>\n",
       "      <td>0.027805</td>\n",
       "      <td>0.048484</td>\n",
       "      <td>0.037782</td>\n",
       "      <td>0.048746</td>\n",
       "      <td>0.014248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143998</th>\n",
       "      <td>0.549499</td>\n",
       "      <td>0.155256</td>\n",
       "      <td>0.016391</td>\n",
       "      <td>0.013969</td>\n",
       "      <td>0.019271</td>\n",
       "      <td>0.010247</td>\n",
       "      <td>0.009601</td>\n",
       "      <td>0.034645</td>\n",
       "      <td>0.032181</td>\n",
       "      <td>0.009958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.000410</td>\n",
       "      <td>0.009907</td>\n",
       "      <td>0.010678</td>\n",
       "      <td>0.008767</td>\n",
       "      <td>0.017730</td>\n",
       "      <td>0.036404</td>\n",
       "      <td>0.023869</td>\n",
       "      <td>0.037465</td>\n",
       "      <td>0.009715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143999</th>\n",
       "      <td>0.479724</td>\n",
       "      <td>0.134604</td>\n",
       "      <td>0.013937</td>\n",
       "      <td>0.013786</td>\n",
       "      <td>0.017540</td>\n",
       "      <td>0.009726</td>\n",
       "      <td>0.008647</td>\n",
       "      <td>0.030391</td>\n",
       "      <td>0.026751</td>\n",
       "      <td>0.009201</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000338</td>\n",
       "      <td>0.000362</td>\n",
       "      <td>0.008551</td>\n",
       "      <td>0.008181</td>\n",
       "      <td>0.008191</td>\n",
       "      <td>0.018414</td>\n",
       "      <td>0.028201</td>\n",
       "      <td>0.022727</td>\n",
       "      <td>0.031700</td>\n",
       "      <td>0.008132</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142560 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         Ptrafo1   Ptrafo2        P1        P2        P3        P4        P5  \\\n",
       "1440    0.337678  0.093012  0.009481  0.009348  0.010640  0.005741  0.005507   \n",
       "1441    0.305996  0.084692  0.009507  0.008017  0.010989  0.005431  0.005488   \n",
       "1442    0.291301  0.079540  0.008719  0.007536  0.010365  0.005265  0.005271   \n",
       "1443    0.277902  0.077530  0.009021  0.007408  0.010420  0.004760  0.004796   \n",
       "1444    0.279065  0.078561  0.008104  0.007931  0.010299  0.004801  0.004836   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "143995  0.857367  0.235687  0.025086  0.023784  0.028559  0.014306  0.014914   \n",
       "143996  0.740003  0.201916  0.020649  0.020129  0.028740  0.013905  0.012886   \n",
       "143997  0.802869  0.220284  0.023419  0.021639  0.027228  0.013467  0.015262   \n",
       "143998  0.549499  0.155256  0.016391  0.013969  0.019271  0.010247  0.009601   \n",
       "143999  0.479724  0.134604  0.013937  0.013786  0.017540  0.009726  0.008647   \n",
       "\n",
       "              P6        P7        P8  ...       Q32       Q33       Q34  \\\n",
       "1440    0.020521  0.020264  0.005551  ...  0.000255  0.000253  0.006299   \n",
       "1441    0.018590  0.018987  0.005639  ...  0.000185  0.000220  0.005627   \n",
       "1442    0.019339  0.018926  0.005178  ...  0.000206  0.000228  0.005530   \n",
       "1443    0.017365  0.016025  0.005020  ...  0.000178  0.000210  0.004860   \n",
       "1444    0.016200  0.016499  0.004801  ...  0.000185  0.000211  0.004941   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "143995  0.050059  0.051772  0.015628  ...  0.000572  0.000698  0.015604   \n",
       "143996  0.046503  0.046473  0.012015  ...  0.000447  0.000611  0.013078   \n",
       "143997  0.050713  0.050593  0.014626  ...  0.000494  0.000631  0.013512   \n",
       "143998  0.034645  0.032181  0.009958  ...  0.000389  0.000410  0.009907   \n",
       "143999  0.030391  0.026751  0.009201  ...  0.000338  0.000362  0.008551   \n",
       "\n",
       "             Q35       Q36       Q37       Q38       Q39       Q40       Q41  \n",
       "1440    0.005716  0.005786  0.012480  0.021099  0.013912  0.021721  0.005749  \n",
       "1441    0.005359  0.005044  0.010697  0.019658  0.013124  0.019688  0.005284  \n",
       "1442    0.005308  0.005564  0.010815  0.017404  0.012537  0.017385  0.004822  \n",
       "1443    0.004929  0.005253  0.010727  0.017573  0.013319  0.015857  0.004839  \n",
       "1444    0.005104  0.004923  0.010776  0.017839  0.012315  0.017587  0.004897  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "143995  0.015474  0.017490  0.028037  0.049220  0.034343  0.057983  0.015990  \n",
       "143996  0.012686  0.012914  0.025388  0.043782  0.033284  0.046765  0.012852  \n",
       "143997  0.013954  0.014343  0.027805  0.048484  0.037782  0.048746  0.014248  \n",
       "143998  0.010678  0.008767  0.017730  0.036404  0.023869  0.037465  0.009715  \n",
       "143999  0.008181  0.008191  0.018414  0.028201  0.022727  0.031700  0.008132  \n",
       "\n",
       "[142560 rows x 82 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cargaP = np.zeros([42, 1000, 144])\n",
    "cargaQ = np.zeros([42, 1000, 144])\n",
    "p = d['CargaP'].transpose()\n",
    "q = d['CargaP'].transpose()\n",
    "\n",
    "for i in range(42):\n",
    "  for j in range(1000):\n",
    "    a = i\n",
    "    for k in range(144):\n",
    "      cargaP[i][j][k] = p[j][a]\n",
    "      cargaQ[i][j][k] = q[j][a]\n",
    "      a = a + 42\n",
    "\n",
    "cargaP = pd.DataFrame(cargaP.reshape(42,144000).transpose())\n",
    "cargaP.columns = [f'P{col_name}' for col_name in cargaP.columns]\n",
    "cargaP = cargaP.drop(['P0','P25'], axis=1)\n",
    "\n",
    "cargaQ = pd.DataFrame(cargaQ.reshape(42,144000).transpose())\n",
    "cargaQ.columns = [f'Q{col_name}' for col_name in cargaQ.columns]\n",
    "cargaQ = cargaQ.drop(['Q0','Q25'], axis=1)\n",
    "\n",
    "X = pd.concat([ptrafo1, ptrafo2, cargaP, cargaQ], axis=1)\n",
    "X2 = X.iloc[:1440,:]\n",
    "X = X.iloc[1440:,:]\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>...</th>\n",
       "      <th>32</th>\n",
       "      <th>33</th>\n",
       "      <th>34</th>\n",
       "      <th>35</th>\n",
       "      <th>36</th>\n",
       "      <th>37</th>\n",
       "      <th>38</th>\n",
       "      <th>39</th>\n",
       "      <th>40</th>\n",
       "      <th>41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1440</th>\n",
       "      <td>1.049755</td>\n",
       "      <td>1.048616</td>\n",
       "      <td>1.047947</td>\n",
       "      <td>1.047283</td>\n",
       "      <td>1.045627</td>\n",
       "      <td>1.045314</td>\n",
       "      <td>1.044880</td>\n",
       "      <td>1.044323</td>\n",
       "      <td>1.043802</td>\n",
       "      <td>1.043725</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046349</td>\n",
       "      <td>1.046316</td>\n",
       "      <td>1.045454</td>\n",
       "      <td>1.045224</td>\n",
       "      <td>1.044192</td>\n",
       "      <td>1.043449</td>\n",
       "      <td>1.043130</td>\n",
       "      <td>1.042769</td>\n",
       "      <td>1.042688</td>\n",
       "      <td>1.042664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1441</th>\n",
       "      <td>1.049777</td>\n",
       "      <td>1.048740</td>\n",
       "      <td>1.048125</td>\n",
       "      <td>1.047518</td>\n",
       "      <td>1.046005</td>\n",
       "      <td>1.045721</td>\n",
       "      <td>1.045326</td>\n",
       "      <td>1.044824</td>\n",
       "      <td>1.044359</td>\n",
       "      <td>1.044291</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046814</td>\n",
       "      <td>1.046785</td>\n",
       "      <td>1.045846</td>\n",
       "      <td>1.045636</td>\n",
       "      <td>1.044691</td>\n",
       "      <td>1.044009</td>\n",
       "      <td>1.043713</td>\n",
       "      <td>1.043382</td>\n",
       "      <td>1.043307</td>\n",
       "      <td>1.043285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1442</th>\n",
       "      <td>1.049789</td>\n",
       "      <td>1.048807</td>\n",
       "      <td>1.048222</td>\n",
       "      <td>1.047644</td>\n",
       "      <td>1.046209</td>\n",
       "      <td>1.045932</td>\n",
       "      <td>1.045553</td>\n",
       "      <td>1.045077</td>\n",
       "      <td>1.044635</td>\n",
       "      <td>1.044570</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046853</td>\n",
       "      <td>1.046822</td>\n",
       "      <td>1.046062</td>\n",
       "      <td>1.045868</td>\n",
       "      <td>1.045000</td>\n",
       "      <td>1.044380</td>\n",
       "      <td>1.044114</td>\n",
       "      <td>1.043812</td>\n",
       "      <td>1.043746</td>\n",
       "      <td>1.043726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1443</th>\n",
       "      <td>1.049798</td>\n",
       "      <td>1.048855</td>\n",
       "      <td>1.048297</td>\n",
       "      <td>1.047747</td>\n",
       "      <td>1.046378</td>\n",
       "      <td>1.046122</td>\n",
       "      <td>1.045769</td>\n",
       "      <td>1.045311</td>\n",
       "      <td>1.044888</td>\n",
       "      <td>1.044826</td>\n",
       "      <td>...</td>\n",
       "      <td>1.047060</td>\n",
       "      <td>1.047032</td>\n",
       "      <td>1.046233</td>\n",
       "      <td>1.046041</td>\n",
       "      <td>1.045180</td>\n",
       "      <td>1.044563</td>\n",
       "      <td>1.044299</td>\n",
       "      <td>1.044003</td>\n",
       "      <td>1.043941</td>\n",
       "      <td>1.043921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1444</th>\n",
       "      <td>1.049797</td>\n",
       "      <td>1.048853</td>\n",
       "      <td>1.048296</td>\n",
       "      <td>1.047747</td>\n",
       "      <td>1.046377</td>\n",
       "      <td>1.046126</td>\n",
       "      <td>1.045775</td>\n",
       "      <td>1.045324</td>\n",
       "      <td>1.044907</td>\n",
       "      <td>1.044844</td>\n",
       "      <td>...</td>\n",
       "      <td>1.046995</td>\n",
       "      <td>1.046967</td>\n",
       "      <td>1.046231</td>\n",
       "      <td>1.046036</td>\n",
       "      <td>1.045164</td>\n",
       "      <td>1.044536</td>\n",
       "      <td>1.044267</td>\n",
       "      <td>1.043964</td>\n",
       "      <td>1.043897</td>\n",
       "      <td>1.043877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143995</th>\n",
       "      <td>1.049380</td>\n",
       "      <td>1.046493</td>\n",
       "      <td>1.044786</td>\n",
       "      <td>1.043096</td>\n",
       "      <td>1.038897</td>\n",
       "      <td>1.038091</td>\n",
       "      <td>1.036963</td>\n",
       "      <td>1.035509</td>\n",
       "      <td>1.034161</td>\n",
       "      <td>1.033960</td>\n",
       "      <td>...</td>\n",
       "      <td>1.040947</td>\n",
       "      <td>1.040853</td>\n",
       "      <td>1.038462</td>\n",
       "      <td>1.037885</td>\n",
       "      <td>1.035321</td>\n",
       "      <td>1.033494</td>\n",
       "      <td>1.032695</td>\n",
       "      <td>1.031740</td>\n",
       "      <td>1.031518</td>\n",
       "      <td>1.031450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143996</th>\n",
       "      <td>1.049464</td>\n",
       "      <td>1.046952</td>\n",
       "      <td>1.045459</td>\n",
       "      <td>1.043993</td>\n",
       "      <td>1.040356</td>\n",
       "      <td>1.039656</td>\n",
       "      <td>1.038691</td>\n",
       "      <td>1.037464</td>\n",
       "      <td>1.036318</td>\n",
       "      <td>1.036148</td>\n",
       "      <td>...</td>\n",
       "      <td>1.042061</td>\n",
       "      <td>1.041979</td>\n",
       "      <td>1.039981</td>\n",
       "      <td>1.039483</td>\n",
       "      <td>1.037257</td>\n",
       "      <td>1.035658</td>\n",
       "      <td>1.034962</td>\n",
       "      <td>1.034147</td>\n",
       "      <td>1.033968</td>\n",
       "      <td>1.033914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143997</th>\n",
       "      <td>1.049418</td>\n",
       "      <td>1.046700</td>\n",
       "      <td>1.045085</td>\n",
       "      <td>1.043486</td>\n",
       "      <td>1.039506</td>\n",
       "      <td>1.038744</td>\n",
       "      <td>1.037694</td>\n",
       "      <td>1.036361</td>\n",
       "      <td>1.035128</td>\n",
       "      <td>1.034946</td>\n",
       "      <td>...</td>\n",
       "      <td>1.041565</td>\n",
       "      <td>1.041480</td>\n",
       "      <td>1.039095</td>\n",
       "      <td>1.038548</td>\n",
       "      <td>1.036102</td>\n",
       "      <td>1.034345</td>\n",
       "      <td>1.033582</td>\n",
       "      <td>1.032695</td>\n",
       "      <td>1.032506</td>\n",
       "      <td>1.032446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143998</th>\n",
       "      <td>1.049599</td>\n",
       "      <td>1.047733</td>\n",
       "      <td>1.046619</td>\n",
       "      <td>1.045518</td>\n",
       "      <td>1.042773</td>\n",
       "      <td>1.042266</td>\n",
       "      <td>1.041571</td>\n",
       "      <td>1.040676</td>\n",
       "      <td>1.039849</td>\n",
       "      <td>1.039726</td>\n",
       "      <td>...</td>\n",
       "      <td>1.044188</td>\n",
       "      <td>1.044133</td>\n",
       "      <td>1.042481</td>\n",
       "      <td>1.042093</td>\n",
       "      <td>1.040354</td>\n",
       "      <td>1.039097</td>\n",
       "      <td>1.038544</td>\n",
       "      <td>1.037923</td>\n",
       "      <td>1.037782</td>\n",
       "      <td>1.037741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143999</th>\n",
       "      <td>1.049653</td>\n",
       "      <td>1.048032</td>\n",
       "      <td>1.047072</td>\n",
       "      <td>1.046126</td>\n",
       "      <td>1.043786</td>\n",
       "      <td>1.043350</td>\n",
       "      <td>1.042752</td>\n",
       "      <td>1.041975</td>\n",
       "      <td>1.041261</td>\n",
       "      <td>1.041154</td>\n",
       "      <td>...</td>\n",
       "      <td>1.044842</td>\n",
       "      <td>1.044794</td>\n",
       "      <td>1.043538</td>\n",
       "      <td>1.043209</td>\n",
       "      <td>1.041740</td>\n",
       "      <td>1.040681</td>\n",
       "      <td>1.040225</td>\n",
       "      <td>1.039680</td>\n",
       "      <td>1.039561</td>\n",
       "      <td>1.039527</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>142560 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              1         2         3         4         5         6         7   \\\n",
       "1440    1.049755  1.048616  1.047947  1.047283  1.045627  1.045314  1.044880   \n",
       "1441    1.049777  1.048740  1.048125  1.047518  1.046005  1.045721  1.045326   \n",
       "1442    1.049789  1.048807  1.048222  1.047644  1.046209  1.045932  1.045553   \n",
       "1443    1.049798  1.048855  1.048297  1.047747  1.046378  1.046122  1.045769   \n",
       "1444    1.049797  1.048853  1.048296  1.047747  1.046377  1.046126  1.045775   \n",
       "...          ...       ...       ...       ...       ...       ...       ...   \n",
       "143995  1.049380  1.046493  1.044786  1.043096  1.038897  1.038091  1.036963   \n",
       "143996  1.049464  1.046952  1.045459  1.043993  1.040356  1.039656  1.038691   \n",
       "143997  1.049418  1.046700  1.045085  1.043486  1.039506  1.038744  1.037694   \n",
       "143998  1.049599  1.047733  1.046619  1.045518  1.042773  1.042266  1.041571   \n",
       "143999  1.049653  1.048032  1.047072  1.046126  1.043786  1.043350  1.042752   \n",
       "\n",
       "              8         9         10  ...        32        33        34  \\\n",
       "1440    1.044323  1.043802  1.043725  ...  1.046349  1.046316  1.045454   \n",
       "1441    1.044824  1.044359  1.044291  ...  1.046814  1.046785  1.045846   \n",
       "1442    1.045077  1.044635  1.044570  ...  1.046853  1.046822  1.046062   \n",
       "1443    1.045311  1.044888  1.044826  ...  1.047060  1.047032  1.046233   \n",
       "1444    1.045324  1.044907  1.044844  ...  1.046995  1.046967  1.046231   \n",
       "...          ...       ...       ...  ...       ...       ...       ...   \n",
       "143995  1.035509  1.034161  1.033960  ...  1.040947  1.040853  1.038462   \n",
       "143996  1.037464  1.036318  1.036148  ...  1.042061  1.041979  1.039981   \n",
       "143997  1.036361  1.035128  1.034946  ...  1.041565  1.041480  1.039095   \n",
       "143998  1.040676  1.039849  1.039726  ...  1.044188  1.044133  1.042481   \n",
       "143999  1.041975  1.041261  1.041154  ...  1.044842  1.044794  1.043538   \n",
       "\n",
       "              35        36        37        38        39        40        41  \n",
       "1440    1.045224  1.044192  1.043449  1.043130  1.042769  1.042688  1.042664  \n",
       "1441    1.045636  1.044691  1.044009  1.043713  1.043382  1.043307  1.043285  \n",
       "1442    1.045868  1.045000  1.044380  1.044114  1.043812  1.043746  1.043726  \n",
       "1443    1.046041  1.045180  1.044563  1.044299  1.044003  1.043941  1.043921  \n",
       "1444    1.046036  1.045164  1.044536  1.044267  1.043964  1.043897  1.043877  \n",
       "...          ...       ...       ...       ...       ...       ...       ...  \n",
       "143995  1.037885  1.035321  1.033494  1.032695  1.031740  1.031518  1.031450  \n",
       "143996  1.039483  1.037257  1.035658  1.034962  1.034147  1.033968  1.033914  \n",
       "143997  1.038548  1.036102  1.034345  1.033582  1.032695  1.032506  1.032446  \n",
       "143998  1.042093  1.040354  1.039097  1.038544  1.037923  1.037782  1.037741  \n",
       "143999  1.043209  1.041740  1.040681  1.040225  1.039680  1.039561  1.039527  \n",
       "\n",
       "[142560 rows x 40 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensao = np.zeros([42, 1000, 144])\n",
    "t = d['Tensao'].transpose()\n",
    "\n",
    "for i in range(42):\n",
    "  for j in range(1000):\n",
    "    a = i\n",
    "    for k in range(144):\n",
    "      tensao[i][j][k] = t[j][a]\n",
    "      a = a + 42\n",
    "\n",
    "tensao = pd.DataFrame(tensao.reshape(42,144000).transpose())\n",
    "Y = tensao.drop([0,25], axis=1)\n",
    "Y2 = Y.iloc[:1440,:]\n",
    "Y = Y.iloc[1440:,:]\n",
    "Y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,Y,test_size=0.3,random_state=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99792, 82)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "X_train= scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(82,activation='relu'))\n",
    "model.add(Dense(40,activation='relu'))\n",
    "model.add(Dense(40))\n",
    "\n",
    "model.compile(optimizer='adam',loss='mae')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "780/780 [==============================] - 5s 5ms/step - loss: 0.0851 - val_loss: 0.0072\n",
      "Epoch 2/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0059 - val_loss: 0.0048\n",
      "Epoch 3/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0058 - val_loss: 0.0033\n",
      "Epoch 4/50\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0052 - val_loss: 0.0115\n",
      "Epoch 5/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0051 - val_loss: 0.0025\n",
      "Epoch 6/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0047 - val_loss: 0.0043\n",
      "Epoch 7/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0076\n",
      "Epoch 8/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0043 - val_loss: 0.0168\n",
      "Epoch 9/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0048 - val_loss: 0.0031\n",
      "Epoch 10/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0046 - val_loss: 0.0021\n",
      "Epoch 11/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0044 - val_loss: 0.0081\n",
      "Epoch 12/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0045 - val_loss: 0.0044\n",
      "Epoch 13/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0042\n",
      "Epoch 14/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0039 - val_loss: 0.0021\n",
      "Epoch 15/50\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0036 - val_loss: 0.0018\n",
      "Epoch 16/50\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0048 - val_loss: 0.0032\n",
      "Epoch 17/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0033 - val_loss: 0.0017\n",
      "Epoch 18/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0034 - val_loss: 0.0090\n",
      "Epoch 19/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0037 - val_loss: 0.0019\n",
      "Epoch 20/50\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 0.0027\n",
      "Epoch 21/50\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0033 - val_loss: 0.0040\n",
      "Epoch 22/50\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0037 - val_loss: 0.0048\n",
      "Epoch 23/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0030\n",
      "Epoch 24/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0054\n",
      "Epoch 25/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0035 - val_loss: 0.0029\n",
      "Epoch 26/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0031 - val_loss: 0.0028\n",
      "Epoch 27/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0028 - val_loss: 0.0063\n",
      "Epoch 28/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 29/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0027 - val_loss: 0.0017\n",
      "Epoch 30/50\n",
      "780/780 [==============================] - 1s 1ms/step - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 31/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 32/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0028 - val_loss: 0.0017\n",
      "Epoch 33/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0028 - val_loss: 0.0049\n",
      "Epoch 34/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 35/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0028 - val_loss: 0.0044\n",
      "Epoch 36/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 37/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0023 - val_loss: 0.0019\n",
      "Epoch 38/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0027 - val_loss: 0.0020\n",
      "Epoch 39/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 40/50\n",
      "780/780 [==============================] - 2s 2ms/step - loss: 0.0026 - val_loss: 0.0014\n",
      "Epoch 41/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0022 - val_loss: 0.0019\n",
      "Epoch 42/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0023 - val_loss: 0.0026\n",
      "Epoch 43/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0021 - val_loss: 0.0024\n",
      "Epoch 44/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0022 - val_loss: 0.0018\n",
      "Epoch 45/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0021 - val_loss: 0.0018\n",
      "Epoch 46/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0020 - val_loss: 0.0011\n",
      "Epoch 47/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.0013\n",
      "Epoch 48/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0022 - val_loss: 0.0013\n",
      "Epoch 49/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.0023\n",
      "Epoch 50/50\n",
      "780/780 [==============================] - 1s 2ms/step - loss: 0.0019 - val_loss: 0.0019\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(x=X_train,y=y_train.values,\n",
    "          validation_data=(X_test,y_test.values),\n",
    "          batch_size=128,epochs=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">0.002\n"
     ]
    }
   ],
   "source": [
    "mae = model.evaluate(X_test, y_test, verbose=0)\n",
    "print('>%.3f' % mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "losses = pd.DataFrame(history.history)\n",
    "losses.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation on Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Ptrafo1</th>\n",
       "      <th>Ptrafo2</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>P6</th>\n",
       "      <th>P7</th>\n",
       "      <th>P8</th>\n",
       "      <th>...</th>\n",
       "      <th>Q32</th>\n",
       "      <th>Q33</th>\n",
       "      <th>Q34</th>\n",
       "      <th>Q35</th>\n",
       "      <th>Q36</th>\n",
       "      <th>Q37</th>\n",
       "      <th>Q38</th>\n",
       "      <th>Q39</th>\n",
       "      <th>Q40</th>\n",
       "      <th>Q41</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.334064</td>\n",
       "      <td>0.094185</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>0.009834</td>\n",
       "      <td>0.012679</td>\n",
       "      <td>0.006414</td>\n",
       "      <td>0.005711</td>\n",
       "      <td>0.019901</td>\n",
       "      <td>0.020760</td>\n",
       "      <td>0.005586</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000216</td>\n",
       "      <td>0.000265</td>\n",
       "      <td>0.005832</td>\n",
       "      <td>0.005882</td>\n",
       "      <td>0.006341</td>\n",
       "      <td>0.011216</td>\n",
       "      <td>0.020954</td>\n",
       "      <td>0.015683</td>\n",
       "      <td>0.021967</td>\n",
       "      <td>0.006054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.294347</td>\n",
       "      <td>0.080567</td>\n",
       "      <td>0.008489</td>\n",
       "      <td>0.007609</td>\n",
       "      <td>0.011114</td>\n",
       "      <td>0.005427</td>\n",
       "      <td>0.005834</td>\n",
       "      <td>0.017792</td>\n",
       "      <td>0.018026</td>\n",
       "      <td>0.005269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000207</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.005177</td>\n",
       "      <td>0.005416</td>\n",
       "      <td>0.005216</td>\n",
       "      <td>0.010498</td>\n",
       "      <td>0.017240</td>\n",
       "      <td>0.012633</td>\n",
       "      <td>0.018994</td>\n",
       "      <td>0.005212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.290302</td>\n",
       "      <td>0.081519</td>\n",
       "      <td>0.008479</td>\n",
       "      <td>0.007208</td>\n",
       "      <td>0.011379</td>\n",
       "      <td>0.005166</td>\n",
       "      <td>0.005292</td>\n",
       "      <td>0.017040</td>\n",
       "      <td>0.016047</td>\n",
       "      <td>0.005139</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>0.000231</td>\n",
       "      <td>0.005106</td>\n",
       "      <td>0.005556</td>\n",
       "      <td>0.005428</td>\n",
       "      <td>0.010461</td>\n",
       "      <td>0.018653</td>\n",
       "      <td>0.012739</td>\n",
       "      <td>0.018057</td>\n",
       "      <td>0.005326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.278100</td>\n",
       "      <td>0.076426</td>\n",
       "      <td>0.008244</td>\n",
       "      <td>0.007869</td>\n",
       "      <td>0.009901</td>\n",
       "      <td>0.005009</td>\n",
       "      <td>0.004862</td>\n",
       "      <td>0.017293</td>\n",
       "      <td>0.016025</td>\n",
       "      <td>0.005315</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000176</td>\n",
       "      <td>0.000234</td>\n",
       "      <td>0.004657</td>\n",
       "      <td>0.005174</td>\n",
       "      <td>0.004779</td>\n",
       "      <td>0.010133</td>\n",
       "      <td>0.016994</td>\n",
       "      <td>0.013142</td>\n",
       "      <td>0.016360</td>\n",
       "      <td>0.005020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.273466</td>\n",
       "      <td>0.077728</td>\n",
       "      <td>0.007704</td>\n",
       "      <td>0.007068</td>\n",
       "      <td>0.010562</td>\n",
       "      <td>0.004872</td>\n",
       "      <td>0.004785</td>\n",
       "      <td>0.016108</td>\n",
       "      <td>0.016280</td>\n",
       "      <td>0.004854</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000193</td>\n",
       "      <td>0.000227</td>\n",
       "      <td>0.005117</td>\n",
       "      <td>0.005032</td>\n",
       "      <td>0.004702</td>\n",
       "      <td>0.010507</td>\n",
       "      <td>0.016470</td>\n",
       "      <td>0.012441</td>\n",
       "      <td>0.018189</td>\n",
       "      <td>0.005102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1435</th>\n",
       "      <td>0.858627</td>\n",
       "      <td>0.238608</td>\n",
       "      <td>0.024715</td>\n",
       "      <td>0.022490</td>\n",
       "      <td>0.032691</td>\n",
       "      <td>0.016515</td>\n",
       "      <td>0.016751</td>\n",
       "      <td>0.052321</td>\n",
       "      <td>0.055362</td>\n",
       "      <td>0.015829</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000552</td>\n",
       "      <td>0.000634</td>\n",
       "      <td>0.016515</td>\n",
       "      <td>0.015085</td>\n",
       "      <td>0.013999</td>\n",
       "      <td>0.027776</td>\n",
       "      <td>0.054340</td>\n",
       "      <td>0.039597</td>\n",
       "      <td>0.054293</td>\n",
       "      <td>0.015319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1436</th>\n",
       "      <td>0.719474</td>\n",
       "      <td>0.191735</td>\n",
       "      <td>0.020099</td>\n",
       "      <td>0.022045</td>\n",
       "      <td>0.026496</td>\n",
       "      <td>0.014187</td>\n",
       "      <td>0.013482</td>\n",
       "      <td>0.041626</td>\n",
       "      <td>0.046050</td>\n",
       "      <td>0.013240</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000506</td>\n",
       "      <td>0.000558</td>\n",
       "      <td>0.012907</td>\n",
       "      <td>0.013126</td>\n",
       "      <td>0.012523</td>\n",
       "      <td>0.026250</td>\n",
       "      <td>0.037829</td>\n",
       "      <td>0.032561</td>\n",
       "      <td>0.043602</td>\n",
       "      <td>0.011955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1437</th>\n",
       "      <td>0.788478</td>\n",
       "      <td>0.221365</td>\n",
       "      <td>0.023183</td>\n",
       "      <td>0.020128</td>\n",
       "      <td>0.029874</td>\n",
       "      <td>0.013558</td>\n",
       "      <td>0.013696</td>\n",
       "      <td>0.047959</td>\n",
       "      <td>0.046747</td>\n",
       "      <td>0.013588</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000563</td>\n",
       "      <td>0.000629</td>\n",
       "      <td>0.014721</td>\n",
       "      <td>0.012102</td>\n",
       "      <td>0.014186</td>\n",
       "      <td>0.027386</td>\n",
       "      <td>0.051533</td>\n",
       "      <td>0.037327</td>\n",
       "      <td>0.048599</td>\n",
       "      <td>0.014034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1438</th>\n",
       "      <td>0.545612</td>\n",
       "      <td>0.150283</td>\n",
       "      <td>0.015778</td>\n",
       "      <td>0.014776</td>\n",
       "      <td>0.020527</td>\n",
       "      <td>0.009373</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>0.033431</td>\n",
       "      <td>0.031021</td>\n",
       "      <td>0.010053</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000376</td>\n",
       "      <td>0.000406</td>\n",
       "      <td>0.009232</td>\n",
       "      <td>0.010148</td>\n",
       "      <td>0.010338</td>\n",
       "      <td>0.020398</td>\n",
       "      <td>0.031058</td>\n",
       "      <td>0.023456</td>\n",
       "      <td>0.034931</td>\n",
       "      <td>0.010101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1439</th>\n",
       "      <td>0.481250</td>\n",
       "      <td>0.134045</td>\n",
       "      <td>0.013914</td>\n",
       "      <td>0.012501</td>\n",
       "      <td>0.016812</td>\n",
       "      <td>0.008405</td>\n",
       "      <td>0.008929</td>\n",
       "      <td>0.029755</td>\n",
       "      <td>0.028396</td>\n",
       "      <td>0.009290</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000312</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>0.008432</td>\n",
       "      <td>0.008274</td>\n",
       "      <td>0.008565</td>\n",
       "      <td>0.017848</td>\n",
       "      <td>0.028767</td>\n",
       "      <td>0.021980</td>\n",
       "      <td>0.030745</td>\n",
       "      <td>0.008922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1440 rows × 82 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Ptrafo1   Ptrafo2        P1        P2        P3        P4        P5  \\\n",
       "0     0.334064  0.094185  0.009734  0.009834  0.012679  0.006414  0.005711   \n",
       "1     0.294347  0.080567  0.008489  0.007609  0.011114  0.005427  0.005834   \n",
       "2     0.290302  0.081519  0.008479  0.007208  0.011379  0.005166  0.005292   \n",
       "3     0.278100  0.076426  0.008244  0.007869  0.009901  0.005009  0.004862   \n",
       "4     0.273466  0.077728  0.007704  0.007068  0.010562  0.004872  0.004785   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "1435  0.858627  0.238608  0.024715  0.022490  0.032691  0.016515  0.016751   \n",
       "1436  0.719474  0.191735  0.020099  0.022045  0.026496  0.014187  0.013482   \n",
       "1437  0.788478  0.221365  0.023183  0.020128  0.029874  0.013558  0.013696   \n",
       "1438  0.545612  0.150283  0.015778  0.014776  0.020527  0.009373  0.009616   \n",
       "1439  0.481250  0.134045  0.013914  0.012501  0.016812  0.008405  0.008929   \n",
       "\n",
       "            P6        P7        P8  ...       Q32       Q33       Q34  \\\n",
       "0     0.019901  0.020760  0.005586  ...  0.000216  0.000265  0.005832   \n",
       "1     0.017792  0.018026  0.005269  ...  0.000207  0.000234  0.005177   \n",
       "2     0.017040  0.016047  0.005139  ...  0.000199  0.000231  0.005106   \n",
       "3     0.017293  0.016025  0.005315  ...  0.000176  0.000234  0.004657   \n",
       "4     0.016108  0.016280  0.004854  ...  0.000193  0.000227  0.005117   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1435  0.052321  0.055362  0.015829  ...  0.000552  0.000634  0.016515   \n",
       "1436  0.041626  0.046050  0.013240  ...  0.000506  0.000558  0.012907   \n",
       "1437  0.047959  0.046747  0.013588  ...  0.000563  0.000629  0.014721   \n",
       "1438  0.033431  0.031021  0.010053  ...  0.000376  0.000406  0.009232   \n",
       "1439  0.029755  0.028396  0.009290  ...  0.000312  0.000360  0.008432   \n",
       "\n",
       "           Q35       Q36       Q37       Q38       Q39       Q40       Q41  \n",
       "0     0.005882  0.006341  0.011216  0.020954  0.015683  0.021967  0.006054  \n",
       "1     0.005416  0.005216  0.010498  0.017240  0.012633  0.018994  0.005212  \n",
       "2     0.005556  0.005428  0.010461  0.018653  0.012739  0.018057  0.005326  \n",
       "3     0.005174  0.004779  0.010133  0.016994  0.013142  0.016360  0.005020  \n",
       "4     0.005032  0.004702  0.010507  0.016470  0.012441  0.018189  0.005102  \n",
       "...        ...       ...       ...       ...       ...       ...       ...  \n",
       "1435  0.015085  0.013999  0.027776  0.054340  0.039597  0.054293  0.015319  \n",
       "1436  0.013126  0.012523  0.026250  0.037829  0.032561  0.043602  0.011955  \n",
       "1437  0.012102  0.014186  0.027386  0.051533  0.037327  0.048599  0.014034  \n",
       "1438  0.010148  0.010338  0.020398  0.031058  0.023456  0.034931  0.010101  \n",
       "1439  0.008274  0.008565  0.017848  0.028767  0.021980  0.030745  0.008922  \n",
       "\n",
       "[1440 rows x 82 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,mean_absolute_error,explained_variance_score\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 0.050325187330647746\n",
      "Mean Squared Error: 0.06767588703494103\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(X2)\n",
    "\n",
    "print(f\"Mean Absolute Error: {mean_absolute_error(Y2,predictions)}\")\n",
    "print(f\"Mean Squared Error: {np.sqrt(mean_squared_error(Y2,predictions))}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1440, 40) <class 'pandas.core.frame.DataFrame'>\n",
      "(144,)\n",
      "(1440, 40) <class 'numpy.ndarray'>\n",
      "(1440,)\n"
     ]
    }
   ],
   "source": [
    "print(Y2.shape,type(Y2))\n",
    "print(np.shape(Y2[10][0:144]))\n",
    "print(predictions.shape, type(predictions))\n",
    "print(np.shape(predictions[: , 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Y2[10][(0*144):((0*144)+144)].values == Y2[10][(3*144):((3*144)+144)].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.arange(144)\n",
    "i=8\n",
    "bar = 12\n",
    "plt.figure(figsize = (13,4.5), dpi = 300)\n",
    "plt.plot(t,predictions[(i*144):((i*144)+144), bar], 'y', label = 'Predictions')\n",
    "plt.plot(t,Y2[bar][(i*144):((i*144)+144)], 'r', label = 'Dataset')\n",
    "plt.show\n",
    "plt.legend(loc='upper right', prop={'size': 10}, framealpha=1)\n",
    "plt.savefig(f\"Voltage Bar{bar}.jpg\")\n",
    "plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "e91837a7a7811ce1baba58a337e6c2f9326166ec5011331d40c820304c9c4380"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('nn')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
